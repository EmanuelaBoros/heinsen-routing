{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smallNORB Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pytorch_extras import RAdam, SingleCycleScheduler\n",
    "from deps.small_norb.smallnorb.dataset import SmallNORBDataset\n",
    "from deps.torch_train_test_loop.torch_train_test_loop import LoopComponent, TrainTestLoop\n",
    "\n",
    "from heinsen_routing import Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * x.sigmoid()\n",
    "\n",
    "\n",
    "class SmallNORBClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, n_objs, n_parts, d_chns):\n",
    "        super().__init__()\n",
    "        self.convolve = nn.Sequential(\n",
    "            nn.BatchNorm2d(2 + 2), nn.Conv2d(2 + 2, d_chns, kernel_size=3), Swish(),\n",
    "            nn.BatchNorm2d(d_chns), nn.Conv2d(d_chns, d_chns, kernel_size=3, stride=2), Swish(),\n",
    "            nn.BatchNorm2d(d_chns), nn.Conv2d(d_chns, d_chns, kernel_size=3), Swish(),\n",
    "            nn.BatchNorm2d(d_chns), nn.Conv2d(d_chns, d_chns, kernel_size=3, stride=2), Swish(),\n",
    "            nn.BatchNorm2d(d_chns), nn.Conv2d(d_chns, d_chns, kernel_size=3), Swish(),\n",
    "            nn.BatchNorm2d(d_chns), nn.Conv2d(d_chns, d_chns, kernel_size=3, stride=2), Swish(),\n",
    "        )\n",
    "        self.compute_a = nn.Sequential(nn.BatchNorm2d(d_chns), nn.Conv2d(d_chns, n_parts, 1))\n",
    "        self.compute_mu = nn.Sequential(nn.BatchNorm2d(d_chns), nn.Conv2d(d_chns, n_parts * 4 * 4, 1))\n",
    "        self.routings = nn.Sequential(\n",
    "            Routing(d_spc=4, d_out=4, n_out=n_parts, d_inp=4, n_iters=3),\n",
    "            Routing(d_spc=4, d_out=4, n_out=n_objs, d_inp=4, n_inp=n_parts, n_iters=3),\n",
    "        )\n",
    "\n",
    "    def add_coord_grid(self, x):\n",
    "        h, w = x.shape[-2:]\n",
    "        coord_grid = torch.stack((\n",
    "            torch.linspace(-1.0, 1.0, steps=h, device=x.device)[:, None].expand(-1, w),\n",
    "            torch.linspace(-1.0, 1.0, steps=w, device=x.device)[None, :].expand(h, -1),\n",
    "        )).expand([*x.shape[:-3], -1, -1, -1])\n",
    "        return torch.cat((x, coord_grid), dim=-3)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        x = self.add_coord_grid(images)                        # [bs, (2 + 2), h, w]\n",
    "        x = self.convolve(x)                                   # [bs, d_chns, h', w']\n",
    "\n",
    "        a = self.compute_a(x)                                  # [bs, n_parts, h', w']\n",
    "        a = a.view(a.shape[0], -1)                             # [bs, (n_parts * h' * w')]\n",
    "\n",
    "        mu = self.compute_mu(x)                                # [bs, (n_parts * 4 * 4), h', w']\n",
    "        mu = mu.view([mu.shape[0], -1, 4, 4, *mu.shape[-2:]])  # [bs, n_parts, 4, 4, h', w']\n",
    "        mu = mu.permute(0, 1, 4, 5, 2, 3).contiguous()         # [bs, n_parts, h', w', 4, 4]\n",
    "        mu = mu.view(mu.shape[0], -1, 4, 4)                    # [bs, (n_parts * h' * w'), 4, 4]\n",
    "\n",
    "        for route in self.routings:\n",
    "            a, mu, _ = route(a, mu)\n",
    "\n",
    "        return a                                               # [bs, n_objs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallnorb = SmallNORBDataset(dataset_root='.data/smallnorb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallNORBTorchDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data, categories, preprocessing):\n",
    "        self.data = data\n",
    "        self.categories = categories\n",
    "        self.preprocess = preprocessing\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        images = np.stack((self.data[i].image_lt, self.data[i].image_rt), axis=-1)  # [96, 96, 2]\n",
    "        images = self.preprocess(images).cuda(device=DEVICE)  # [2, 96, 96]\n",
    "        category = torch.tensor(self.data[i].category, dtype=torch.long).cuda(device=DEVICE)\n",
    "        return { 'images': images, 'category': category, }\n",
    "\n",
    "random_crops = tv.transforms.Compose([\n",
    "    tv.transforms.ToPILImage(),\n",
    "    tv.transforms.RandomCrop(size=96, padding=16, padding_mode='edge'),\n",
    "    tv.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Normally we would divide train set into train/valid splits; we don't here to match other papers.\n",
    "trn_ds = SmallNORBTorchDataset(smallnorb.data['train'], smallnorb.categories, random_crops)\n",
    "val_ds = SmallNORBTorchDataset(smallnorb.data['test'], smallnorb.categories, random_crops)\n",
    "tst_ds = SmallNORBTorchDataset(smallnorb.data['test'], smallnorb.categories, tv.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoopMain(LoopComponent):\n",
    "\n",
    "    def __init__(self, n_classes, device, pct_warmup=0.1, mixup=(0.2, 0.2)):\n",
    "        self.n_classes, self.device, self.pct_warmup = (n_classes, device, pct_warmup)\n",
    "        self.mixup_dist = torch.distributions.Beta(torch.tensor(mixup[0]), torch.tensor(mixup[1]))\n",
    "        self.to_onehot = torch.eye(self.n_classes, device=self.device)\n",
    "\n",
    "    def on_train_begin(self, loop):\n",
    "        n_iters = len(loop.train_data) * loop.n_epochs\n",
    "        loop.optimizer = RAdam(loop.model.parameters(), lr=5e-4)\n",
    "        loop.scheduler = SingleCycleScheduler(loop.optimizer, loop.n_optim_steps, frac=self.pct_warmup, min_lr=1e-5)\n",
    "\n",
    "    def on_grads_reset(self, loop):\n",
    "        loop.model.zero_grad()\n",
    "\n",
    "    def on_forward_pass(self, loop):\n",
    "        images, category = loop.batch['images'], loop.batch['category']\n",
    "        target_probs = self.to_onehot[category]\n",
    "\n",
    "        if loop.is_training:\n",
    "            r = self.mixup_dist.sample([len(images)]).to(device=images.device)\n",
    "            idx = torch.randperm(len(images))\n",
    "            images = images.lerp(images[idx], r[:, None, None, None])\n",
    "            target_probs = target_probs.lerp(target_probs[idx], r[:, None])\n",
    "\n",
    "        pred_scores = model(images)\n",
    "        _, pred_ids = pred_scores.max(-1)\n",
    "        accuracy = (pred_ids == category).float().mean()\n",
    "\n",
    "        loop.pred_scores, loop.target_probs, loop.accuracy = (pred_scores, target_probs, accuracy)\n",
    "\n",
    "    def on_loss_compute(self, loop):\n",
    "        losses = -loop.target_probs * F.log_softmax(loop.pred_scores, dim=-1)  # smooth cross entropy\n",
    "        loop.loss = losses.sum(dim=-1).mean()  # sum across classes, then mean of batch\n",
    "\n",
    "    def on_backward_pass(self, loop):\n",
    "        loop.loss.backward()\n",
    "\n",
    "    def on_optim_step(self, loop):\n",
    "        loop.optimizer.step()\n",
    "        loop.scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoopProgressBar(LoopComponent):\n",
    "\n",
    "    def __init__(self, item_names=['loss', 'accuracy']):\n",
    "        self.item_names = item_names\n",
    "\n",
    "    def on_epoch_begin(self, loop):\n",
    "        self.total, self.count = ({ name: 0.0 for name in self.item_names }, 0)\n",
    "        self.pbar = tqdm(total=loop.n_batches, desc=f\"{loop.epoch_desc} epoch {loop.epoch_num}\")\n",
    "\n",
    "    def on_batch_end(self, loop):\n",
    "        n = len(loop.batch['images'])\n",
    "        self.count += n\n",
    "        for name in self.item_names:\n",
    "            self.total[name] += getattr(loop, name).item() * n\n",
    "        self.pbar.update(1)\n",
    "        if (not loop.is_training):\n",
    "            self.pbar.set_postfix(self.mean)\n",
    "\n",
    "    def on_epoch_end(self, loop):\n",
    "        self.pbar.close()\n",
    "\n",
    "    @property\n",
    "    def mean(self): return { f'mean_{name}': self.total[name] / self.count for name in self.item_names }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Seed RNG for replicability.\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Make iterators for each split, with random shuffling in train set.\n",
    "trn_itr = torch.utils.data.DataLoader(trn_ds, batch_size=20, shuffle=True)\n",
    "val_itr = torch.utils.data.DataLoader(val_ds, batch_size=20, shuffle=False)\n",
    "tst_itr = torch.utils.data.DataLoader(tst_ds, batch_size=20, shuffle=False)\n",
    "\n",
    "# Initialize model.\n",
    "n_classes = len(trn_ds.categories)\n",
    "model = SmallNORBClassifier(n_objs=n_classes, n_parts=64, d_chns=64)\n",
    "model = model.cuda(device=DEVICE)\n",
    "\n",
    "# Train model\n",
    "loop = TrainTestLoop(model, [LoopMain(n_classes, DEVICE), LoopProgressBar()], trn_itr, val_itr)\n",
    "loop.train(n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop.test(tst_itr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
